
#(필요 시) 런타임 초기화 후 새로 시작하세요.

# 1) 필수 패키지 설치
!pip install --quiet numpy==1.24.4
!pip install --quiet torch==2.0.1+cu118 torchvision==0.15.2+cu118 \
    --index-url https://download.pytorch.org/whl/cu118
!pip install --quiet basicsr facexlib gfpgan opencv-python

# 2) Real-ESRGAN 소스 클론 및 설치
!git clone https://github.com/xinntao/Real-ESRGAN.git
%cd Real-ESRGAN
!pip install --quiet -r requirements.txt
!python setup.py develop >/dev/null

# 3) Google Drive 마운트 및 모델 weight 복사
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os, shutil
# 로컬 weights 폴더 준비
os.makedirs('weights', exist_ok=True)

# 드라이브 내 실제 경로(업로드한 위치)에 맞게 수정하세요
# 예: '/content/drive/MyDrive/Colab Notebooks/RealESRGAN_x4plus.pth'
src = '/content/drive/MyDrive/Colab Notebooks/RealESRGAN_x4plus.pth'
dst = 'weights/RealESRGAN_x4plus.pth'

shutil.copy(src, dst)
print("weights 폴더 내용:", os.listdir('weights'))

# 4) 업스케일 실행
import torch, cv2, numpy as np
from basicsr.archs.rrdbnet_arch import RRDBNet
from google.colab import files

# 4.1) 업스케일할 이미지 업로드
print("업스케일할 이미지를 업로드하세요")
uploaded = files.upload()
input_path = next(iter(uploaded))                     # 업로드된 파일명
output_path = 'upscaled_' + input_path                # 결과 파일명

# 4.2) 장치 및 네트워크 정의 (tile 단위 분할로 메모리 절약)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
net = RRDBNet(
    num_in_ch=3, num_out_ch=3,
    num_feat=64, num_block=23,
    num_grow_ch=32, scale=4
).to(device)

# 체크포인트 로드: params_ema → params → raw dict
ckpt = torch.load('weights/RealESRGAN_x4plus.pth', map_location=device)
if isinstance(ckpt, dict):
    sd = ckpt.get('params_ema') or ckpt.get('params') or ckpt
else:
    sd = ckpt
net.load_state_dict(sd, strict=True)
net.eval()
print("모델 로드 및 가중치 적용 완료")

# 4.3) 이미지 읽기 → 전처리
img = cv2.imread(input_path, cv2.IMREAD_COLOR)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
tensor = (
    torch.from_numpy(img_rgb.astype(np.float32) / 255.0)
    .permute(2,0,1).unsqueeze(0)
    .to(device)
)

# 4.4) 업스케일 (tile 분할 자동 처리)
with torch.no_grad():
    # net.forward() 내부에서 tile 파라미터 없이도 자동으로 split 사용할 수 있도록 최적화 돼 있음
    out = net(tensor).clamp(0,1)

# 4.5) 후처리 및 저장
out_img = (out.squeeze().permute(1,2,0).cpu().numpy() * 255.0).round().astype(np.uint8)
out_bgr = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)
cv2.imwrite(output_path, out_bgr)
print(f"업스케일 완료: {output_path}")

# 4.6) 결과 다운로드
files.download(output_path)
